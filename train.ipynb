{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:15.935739400Z",
     "start_time": "2023-07-19T07:07:13.886251300Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from paddle import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "    \"input_size\": [\n",
    "        3,\n",
    "        64,\n",
    "        64\n",
    "    ],\n",
    "    \"class_dim\": 102,\n",
    "    \"src_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset.zip\",\n",
    "    \"target_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset\\\\\",\n",
    "    \"image_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset\\\\dataset\\\\images\\\\\",\n",
    "    \"train_list_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset\\\\train.txt\",\n",
    "    \"eval_list_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset\\\\eval.txt\",\n",
    "    \"class_list_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset\\\\dataset\\\\class.txt\",\n",
    "    \"readme_path\": \"E:\\\\Python\\\\CaltechClassification\\\\data\\\\dataset\\\\readme.json\",\n",
    "    \"label_dict\": {\n",
    "    },\n",
    "    \"num_epochs\": 2,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"learning_strategy\": {\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:15.945969100Z",
     "start_time": "2023-07-19T07:07:13.862679400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.数据准备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def unzip_data(src_path, target_path):\n",
    "    \"\"\"\n",
    "    解压原始数据集，将src_path路径下的zip包解压至target_path目录下\n",
    "    :param src_path:  zip包\n",
    "    :param target_path:  目标目录\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(target_path):\n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "\n",
    "\n",
    "def get_data_list(target_path, train_list_path, image_path, class_list_path, readme_path):\n",
    "    \"\"\"\n",
    "    生成数据列表\n",
    "    :param target_path: 目标文件夹\n",
    "    :param train_list_path: 训练列表\n",
    "    :param image_path: 图片路径\n",
    "    :param class_list_path: 标签文件路径\n",
    "    :param readme_path: readme 文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 训练集图片路径\n",
    "    train_data_paths = []\n",
    "    # 训练集图片标签\n",
    "    train_data_labels = []\n",
    "    # 训练集\n",
    "    train_list = []\n",
    "    # 所有图片数量\n",
    "    all_class_images = 0\n",
    "    # 标签类别\n",
    "    class_detail = []\n",
    "    # 训练集文本\n",
    "    train_data_list = open(target_path + \"dataset\\\\train.txt\", \"r\").readlines()\n",
    "    # 标签集\n",
    "    class_data_list = open(class_list_path, \"r\").readlines()\n",
    "    # 标签对应的图片数\n",
    "    class_num = {}\n",
    "\n",
    "    # 生成train.txt\n",
    "    for train_data in train_data_list:\n",
    "        train_data_path = image_path.replace(\"\\\\\", \"\\\\\\\\\") + train_data.split(\"\\t\")[0]\n",
    "        train_data_label = train_data.split(\"\\t\")[1].replace(\"\\n\", \"\")\n",
    "\n",
    "        train_data_paths.append(train_data_path)\n",
    "        train_data_labels.append(train_data_labels)\n",
    "\n",
    "        train_list.append(f\"{train_data_path}\\t{train_data_label}\\n\")\n",
    "\n",
    "        # 统计对应标签的训练集数量\n",
    "        if train_data_label not in class_num.keys():\n",
    "            class_num.setdefault(train_data_label, 0)\n",
    "        class_num[train_data_label] += 1\n",
    "\n",
    "    # 乱序\n",
    "    random.shuffle(train_list)\n",
    "\n",
    "    # 写入 train.txt\n",
    "    with open(train_list_path, \"a\") as f:\n",
    "        for train_data in train_list:\n",
    "            f.write(train_data)\n",
    "\n",
    "    # 生成标签集\n",
    "    for class_data in class_data_list:\n",
    "        class_name = class_data.split(\"\\t\")[0]\n",
    "        class_label = class_data.split(\"\\t\")[1].replace(\"\\n\", \"\")\n",
    "        # 标签类别默认内容\n",
    "        class_detail_default = {\"class_train_images\": class_num[class_label], \"class_label\": int(class_label),\n",
    "                                \"class_name\": class_name}\n",
    "        class_detail.append(class_detail_default)\n",
    "\n",
    "    all_class_images = len(train_data_paths)\n",
    "\n",
    "    # 写入 readme\n",
    "    readme_json = {\"all_class_images\": all_class_images, \"class_detail\": class_detail}\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(json.dumps(readme_json, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "\n",
    "    print(\"数据生成完成\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:15.956054Z",
     "start_time": "2023-07-19T07:07:15.945969100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成完成\n"
     ]
    }
   ],
   "source": [
    "unzip_data(train_parameters[\"src_path\"], train_parameters[\"target_path\"])\n",
    "get_data_list(train_parameters[\"target_path\"], train_parameters[\"train_list_path\"], train_parameters[\"image_path\"],\n",
    "              train_parameters[\"class_list_path\"], train_parameters[\"readme_path\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:15.985896900Z",
     "start_time": "2023-07-19T07:07:15.956054Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.模型搭建"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class caltech_dataset(paddle.io.Dataset):\n",
    "    def __init__(self, data_path, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        数据读取器\n",
    "        :param data_path: 文件路径\n",
    "        :param mode: 读取模式\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        if mode == \"train\":\n",
    "            with open(os.path.join(self.data_path, \"train.txt\"), \"r\", encoding=\"utf8\") as f:\n",
    "                self.info = f.readlines()\n",
    "            for image_info in self.info:\n",
    "                image_path, image_label = image_info.strip().split(\"\\t\")\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(image_label)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        image = Image.open(image_path)\n",
    "        if not image.mode == \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        image = image.resize((64, 64), Image.BILINEAR)\n",
    "        image = np.array(image).astype(\"float32\")\n",
    "        image = image.transpose((2, 0, 1)) / 255\n",
    "        label = np.array([label], dtype=\"int64\")\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:15.996274800Z",
     "start_time": "2023-07-19T07:07:15.985896900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class caltech_model(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(caltech_model, self).__init__()\n",
    "        # 62 * 62\n",
    "        self.conv1 = nn.Conv2D(in_channels=3, out_channels=64, kernel_size=3, padding=0, stride=1)\n",
    "        # 31 * 31\n",
    "        self.pool1 = nn.MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 29 * 29\n",
    "        self.conv2 = nn.Conv2D(in_channels=64, out_channels=128, kernel_size=3, padding=0, stride=1)\n",
    "        # 14 * 14\n",
    "        self.pool2 = nn.MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 10 * 10\n",
    "        self.conv3 = nn.Conv2D(in_channels=128, out_channels=128, kernel_size=5, padding=0, stride=1)\n",
    "        # 5 * 5\n",
    "        self.pool3 = nn.MaxPool2D(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=5 * 5 * 128, out_features=25)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = paddle.reshape(x, [-1, 5 * 5 * 128])\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:16.036054400Z",
     "start_time": "2023-07-19T07:07:15.996274800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "Batch = 0\n",
    "Batchs = []\n",
    "all_train_accs = []\n",
    "\n",
    "\n",
    "def draw_train_acc(Batchs, train_accs):\n",
    "    title = \"training accs\"\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"batch\", fontsize=14)\n",
    "    plt.ylabel(\"acc\", fontsize=14)\n",
    "    plt.plot(Batchs, train_accs, color='green', label='training accs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "all_train_loss = []\n",
    "\n",
    "\n",
    "def draw_train_loss(Batchs, train_loss):\n",
    "    title = \"training loss\"\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"batch\", fontsize=14)\n",
    "    plt.ylabel(\"loss\", fontsize=14)\n",
    "    plt.plot(Batchs, train_loss, color='red', label='training loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:16.046129700Z",
     "start_time": "2023-07-19T07:07:16.006175300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataset = caltech_dataset(train_parameters[\"target_path\"])\n",
    "train_dataloader = paddle.io.DataLoader(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:16.046129700Z",
     "start_time": "2023-07-19T07:07:16.016236400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "(External) CUDNN error(8), CUDNN_STATUS_EXECUTION_FAILED. \n  [Hint: Please search for the error code(8) on website (https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnStatus_t) to get Nvidia's official solution and advice about CUDNN Error.] (at C:\\home\\workspace\\Paddle\\paddle\\phi\\kernels\\gpudnn\\pool_grad_kernel.cu:284)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_id \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m batch_id \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m20\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     23\u001B[0m     paddle\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./checkpoints/caltech_dataset_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(batch_id)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     27\u001B[0m opt\u001B[38;5;241m.\u001B[39mclear_grad()\n",
      "File \u001B[1;32mG:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[0;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[1;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py:26\u001B[0m, in \u001B[0;36mwrap_decorator.<locals>.__impl__\u001B[1;34m(func, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;129m@decorator\u001B[39m\u001B[38;5;241m.\u001B[39mdecorator\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__impl__\u001B[39m(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     25\u001B[0m     wrapped_func \u001B[38;5;241m=\u001B[39m decorator_func(func)\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\framework.py:534\u001B[0m, in \u001B[0;36m_dygraph_only_.<locals>.__impl__\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    529\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__impl__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    530\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m _non_static_mode(), (\n\u001B[0;32m    531\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe only support \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in dynamic graph mode, please call \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaddle.disable_static()\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to enter dynamic graph mode.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    532\u001B[0m         \u001B[38;5;241m%\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m    533\u001B[0m     )\n\u001B[1;32m--> 534\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\varbase_patch_methods.py:297\u001B[0m, in \u001B[0;36mmonkey_patch_varbase.<locals>.backward\u001B[1;34m(self, grad_tensor, retain_graph)\u001B[0m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m framework\u001B[38;5;241m.\u001B[39m_in_eager_mode_:\n\u001B[1;32m--> 297\u001B[0m         \u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    299\u001B[0m         core\u001B[38;5;241m.\u001B[39mdygraph_run_backward([\u001B[38;5;28mself\u001B[39m], [grad_tensor],\n\u001B[0;32m    300\u001B[0m                                   retain_graph,\n\u001B[0;32m    301\u001B[0m                                   framework\u001B[38;5;241m.\u001B[39m_dygraph_tracer())\n",
      "\u001B[1;31mOSError\u001B[0m: (External) CUDNN error(8), CUDNN_STATUS_EXECUTION_FAILED. \n  [Hint: Please search for the error code(8) on website (https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnStatus_t) to get Nvidia's official solution and advice about CUDNN Error.] (at C:\\home\\workspace\\Paddle\\paddle\\phi\\kernels\\gpudnn\\pool_grad_kernel.cu:284)\n"
     ]
    }
   ],
   "source": [
    "model = caltech_model()\n",
    "model.train()\n",
    "cross_entropy = paddle.nn.CrossEntropyLoss()\n",
    "opt = paddle.optimizer.SGD(learning_rate=train_parameters[\"learning_strategy\"][\"lr\"], parameters=model.parameters())\n",
    "epoch_num = train_parameters[\"num_epochs\"]\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_id, data in enumerate(train_dataloader):\n",
    "        img = data[0]\n",
    "        label = data[1]\n",
    "        predict = model(img)\n",
    "        loss = cross_entropy(predict, label)\n",
    "        acc = paddle.metric.accuracy(predict, label.reshape([-1, 1]))\n",
    "\n",
    "        if batch_id != 0 and batch_id % 10 == 0:\n",
    "            Batch = Batch + 10\n",
    "            Batchs.append(Batch)\n",
    "            all_train_loss.append(loss.numpy()[0])\n",
    "            all_train_accs.append(acc.numpy()[0])\n",
    "            print(\"epoch:{},step:{},train_loss:{},train_acc:{}\".format(epoch, batch_id, loss.numpy()[0],\n",
    "                                                                       acc.numpy()[0]))\n",
    "        if batch_id != 0 and batch_id % 20 == 0:\n",
    "            paddle.save(model.state_dict(), f\"./checkpoints/caltech_dataset_{str(batch_id)}\")\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_grad()\n",
    "\n",
    "paddle.save(model.state_dict(), f\"./checkpoints/caltech_dataset_last\")  #保存模型\n",
    "draw_train_acc(Batchs, all_train_accs)\n",
    "draw_train_loss(Batchs, all_train_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T07:07:24.932789400Z",
     "start_time": "2023-07-19T07:07:16.036054400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.结果预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    '''\n",
    "    预测图片预处理\n",
    "    '''\n",
    "    image = Image.open(img_path)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = image.resize((64, 64), Image.BILINEAR)\n",
    "    image = np.array(image).astype('float32')\n",
    "    image = image.transpose((2, 0, 1))  # HWC to CHW\n",
    "    image = image / 255  # 像素值归一化\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "para_state_dict = paddle.load(\"./checkpoints/caltech_dataset_last\")\n",
    "model = caltech_model()\n",
    "model.set_state_dict(para_state_dict)\n",
    "\n",
    "infer_image_path = \"\"\n",
    "infer_images = open(infer_image_path, 'r').readlines()\n",
    "\n",
    "infer_image_list = []\n",
    "\n",
    "for infer_image in infer_images:\n",
    "    infer_image_list.append(os.path.join(train_parameters[\"image_path\"], load_image(infer_image)))\n",
    "\n",
    "infer_image_list = np.array(infer_image_list)\n",
    "\n",
    "outs = []\n",
    "\n",
    "for i in range(infer_image_list):\n",
    "    dy_x_data = np.array(infer_image_list[i]).astype('float32')\n",
    "    dy_x_data = dy_x_data[np.newaxis, :, :, :]\n",
    "    img = paddle.to_tensor(dy_x_data)\n",
    "    out = model(img)\n",
    "    lab = np.argmax(out.numpy())  #argmax():返回最大数的索引\n",
    "    print(lab)\n",
    "    outs.append(f\"{infer_images[i]}\\t{lab}\")\n",
    "print(\"结束\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
